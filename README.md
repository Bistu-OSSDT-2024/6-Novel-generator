# 论文分析器
## 小组成员
张景元、陈佳圻、张曦文、韩欣雨、胡雯宇
## 小组分工
张景元：项目文档 项目构思 整合报告  
陈佳圻：制作ppt 选择许可证 项目描述和计划  
张曦文：代码开发  
韩欣雨：代码开发 项目汇报  
胡雯宇：代码开发
## 许可证
BSD 3-Clause License
## 项目描述
本项目的目标是使用Python编程语言和metagpt库中的DataInterpreter类，自动从arXiv网站上抓取计算机科学领域的论文，并对这些论文进行一系列的数据处理和分析。具体而言，本项目的目的包括以下几个方面：
数据抓取：项目将编写一个自动化脚本，用于从arXiv网站上检索特定计算机科学领域的最新一周的论文列表。
数据解释与处理：利用metagpt库中的DataInterpreter类，项目将对抓取到的论文数据进行深入的解释和处理。这包括提取论文的元数据（如标题、作者、发布日期、摘要等），并可能涉及对文本内容的进一步分析。
去重处理：由于同一篇论文可能在不同领域分类下重复出现，项目将实现一个去重机制，以确保每个论文只被处理一次。这通常通过比较论文的唯一标识符（如ID）来实现。
内容过滤：为了聚焦于特定研究领域，项目将实现一个过滤机制，以排除与大型语言模型、代理或LLM（大型语言模型）相关的论文。这可以通过关键词匹配或基于自然语言处理的技术来实现。
数据分析与可视化：项目将分析处理后的论文数据，特别是论文的标题。首先，将提取前100篇论文的标题，并进行词数统计。随后，使用可视化工具（如matplotlib或seaborn）绘制词数分布的图表，以便直观地展示数据。
